{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment is to try out the leads found in https://claude.ai/chat/110cfe52-6cbc-4bb1-95b0-bdc830de908e (edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common problem in signal processing, especially when dealing with noisy data. Here are a few approaches you could use:\n",
    "\n",
    "1. Peak Prominence Method\n",
    "- Instead of just looking at local maxima, consider the \"prominence\" of each peak\n",
    "- A peak's prominence is the height difference between the peak and the highest point between it and a higher peak\n",
    "\n",
    "2. Smoothing the Signal\n",
    "- Apply smoothing techniques before finding peaks to reduce noise:\n",
    "  - Moving average\n",
    "  - Gaussian smoothing\n",
    "  - Savitzky-Golay filter (particularly good for preserving peak shapes)\n",
    "\n",
    "3. Peak Width Method\n",
    "- Consider peaks that have a minimum width\n",
    "- This helps eliminate narrow noise spikes\n",
    "\n",
    "Let me create a Python implementation that demonstrates these approaches:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "def find_significant_peaks(arr, method='prominence', **kwargs):\n",
    "    \"\"\"\n",
    "    Find significant peaks in array using different methods.\n",
    "    \n",
    "    Parameters:\n",
    "    arr : array-like\n",
    "        Input signal\n",
    "    method : str\n",
    "        'prominence' - Use peak prominence\n",
    "        'width' - Use peak width\n",
    "        'smooth_prominence' - Smooth signal first, then use prominence\n",
    "        'smooth_savgol' - Use Savitzky-Golay filter before finding peaks\n",
    "    \n",
    "    kwargs:\n",
    "        prominence: minimum prominence for peaks\n",
    "        width: minimum width for peaks\n",
    "        window_size: size of smoothing window\n",
    "        polyorder: polynomial order for Savitzky-Golay filter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set default parameters\n",
    "    prominence = kwargs.get('prominence', 1.0)\n",
    "    width = kwargs.get('width', 1)\n",
    "    window_size = kwargs.get('window_size', 5)\n",
    "    polyorder = kwargs.get('polyorder', 2)\n",
    "    \n",
    "    if method == 'prominence':\n",
    "        # Find peaks with minimum prominence\n",
    "        peaks, _ = find_peaks(arr, prominence=prominence)\n",
    "        \n",
    "    elif method == 'width':\n",
    "        # Find peaks with minimum width\n",
    "        peaks, _ = find_peaks(arr, width=width)\n",
    "        \n",
    "    elif method == 'smooth_prominence':\n",
    "        # Apply moving average smoothing\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed = np.convolve(arr, kernel, mode='valid')\n",
    "        peaks, _ = find_peaks(smoothed, prominence=prominence)\n",
    "        # Adjust peak indices for valid convolution\n",
    "        peaks += window_size // 2\n",
    "        \n",
    "    elif method == 'smooth_savgol':\n",
    "        # Apply Savitzky-Golay filter\n",
    "        smoothed = savgol_filter(arr, window_size, polyorder)\n",
    "        peaks, _ = find_peaks(smoothed, prominence=prominence)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "def analyze_peaks(arr, peaks):\n",
    "    \"\"\"\n",
    "    Analyze the detected peaks and return relevant statistics\n",
    "    \"\"\"\n",
    "    peak_values = arr[peaks]\n",
    "    peak_stats = {\n",
    "        'num_peaks': len(peaks),\n",
    "        'mean_peak_height': np.mean(peak_values),\n",
    "        'std_peak_height': np.std(peak_values),\n",
    "        'peak_positions': peaks,\n",
    "        'peak_values': peak_values\n",
    "    }\n",
    "    return peak_stats\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample noisy data\n",
    "    x = np.linspace(0, 10, 1000)\n",
    "    # Create signal with two main peaks\n",
    "    signal = 3*np.sin(x) + np.sin(5*x)\n",
    "    # Add noise\n",
    "    noisy_signal = signal + np.random.normal(0, 0.5, signal.shape)\n",
    "    \n",
    "    # Try different methods\n",
    "    methods = ['prominence', 'width', 'smooth_prominence', 'smooth_savgol']\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        peaks = find_significant_peaks(noisy_signal, method=method, \n",
    "                                     prominence=1.0, width=20, \n",
    "                                     window_size=51, polyorder=3)\n",
    "        results[method] = analyze_peaks(noisy_signal, peaks)\n",
    "\n",
    "```\n",
    "\n",
    "This implementation provides several key features:\n",
    "\n",
    "1. Multiple detection methods:\n",
    "   - Pure prominence-based detection\n",
    "   - Width-based detection\n",
    "   - Smoothed signal with prominence detection\n",
    "   - Savitzky-Golay filtered signal with peak detection\n",
    "\n",
    "2. Configurable parameters:\n",
    "   - Minimum prominence threshold\n",
    "   - Minimum peak width\n",
    "   - Smoothing window size\n",
    "   - Polynomial order for Savitzky-Golay filter\n",
    "\n",
    "3. Peak analysis functionality that provides statistics about detected peaks\n",
    "\n",
    "To use this for your specific case, I'd recommend:\n",
    "\n",
    "1. Start with the 'smooth_savgol' method, as it's generally good at preserving peak shapes while removing noise\n",
    "2. Adjust the window_size parameter based on your signal's characteristics:\n",
    "   - Larger window = more smoothing but might miss closer peaks\n",
    "   - Smaller window = less smoothing but might detect noise\n",
    "3. Tune the prominence parameter to match the minimum significant peak height you care about\n",
    "\n",
    "Would you like me to explain how to tune these parameters for your specific data, or would you like to see an example with visualizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "fp = \"/media/vedant/New Volume/DPythonProjects/yt_summarizer\"\n",
    "\n",
    "sys.path.insert(1, fp)   \n",
    "fp = \"/media/vedant/New Volume/DPythonProjects/yt_summarizer/v2\"\n",
    "\n",
    "sys.path.insert(1, fp)   \n",
    "\n",
    "from v2.helper import Helper\n",
    "\n",
    "Helper.log(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processed_frame import ProcessedFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames : ProcessedFrame = Helper.load_python_object(\"../v2/data/zypvgn_python_object/processed_frames.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_signal, y = ProcessedFrame.get_data_for_plotting(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 90, 180, 270, 360]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_signal[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedant/miniconda3/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vedant/miniconda3/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/vedant/miniconda3/lib/python3.12/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/vedant/miniconda3/lib/python3.12/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/vedant/miniconda3/lib/python3.12/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "def find_significant_peaks(arr, method='prominence', **kwargs):\n",
    "    \"\"\"\n",
    "    Find significant peaks in array using different methods.\n",
    "    \n",
    "    Parameters:\n",
    "    arr : array-like\n",
    "        Input signal\n",
    "    method : str\n",
    "        'prominence' - Use peak prominence\n",
    "        'width' - Use peak width\n",
    "        'smooth_prominence' - Smooth signal first, then use prominence\n",
    "        'smooth_savgol' - Use Savitzky-Golay filter before finding peaks\n",
    "    \n",
    "    kwargs:\n",
    "        prominence: minimum prominence for peaks\n",
    "        width: minimum width for peaks\n",
    "        window_size: size of smoothing window\n",
    "        polyorder: polynomial order for Savitzky-Golay filter\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set default parameters\n",
    "    prominence = kwargs.get('prominence', 1.0)\n",
    "    width = kwargs.get('width', 1)\n",
    "    window_size = kwargs.get('window_size', 5)\n",
    "    polyorder = kwargs.get('polyorder', 2)\n",
    "    \n",
    "    if method == 'prominence':\n",
    "        # Find peaks with minimum prominence\n",
    "        peaks, _ = find_peaks(arr, prominence=prominence)\n",
    "        \n",
    "    elif method == 'width':\n",
    "        # Find peaks with minimum width\n",
    "        peaks, _ = find_peaks(arr, width=width)\n",
    "        \n",
    "    elif method == 'smooth_prominence':\n",
    "        # Apply moving average smoothing\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        smoothed = np.convolve(arr, kernel, mode='valid')\n",
    "        peaks, _ = find_peaks(smoothed, prominence=prominence)\n",
    "        # Adjust peak indices for valid convolution\n",
    "        peaks += window_size // 2\n",
    "        \n",
    "    elif method == 'smooth_savgol':\n",
    "        # Apply Savitzky-Golay filter\n",
    "        smoothed = savgol_filter(arr, window_size, polyorder)\n",
    "        peaks, _ = find_peaks(smoothed, prominence=prominence)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "def analyze_peaks(arr, peaks):\n",
    "    \"\"\"\n",
    "    Analyze the detected peaks and return relevant statistics\n",
    "    \"\"\"\n",
    "    peak_values = arr[peaks]\n",
    "    peak_stats = {\n",
    "        'num_peaks': len(peaks),\n",
    "        'mean_peak_height': np.mean(peak_values),\n",
    "        'std_peak_height': np.std(peak_values),\n",
    "        'peak_positions': peaks,\n",
    "        'peak_values': peak_values\n",
    "    }\n",
    "    return peak_stats\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample noisy data\n",
    "    # x = np.linspace(0, 10, 1000)\n",
    "    # Create signal with two main peaks\n",
    "    # signal = 3*np.sin(x) + np.sin(5*x)\n",
    "    # Add noise\n",
    "    # noisy_signal = signal + np.random.normal(0, 0.5, signal.shape)\n",
    "    \n",
    "    # Try different methods\n",
    "    methods = ['prominence', 'width', 'smooth_prominence', 'smooth_savgol']\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        peaks = find_significant_peaks(noisy_signal, method=method, \n",
    "                                     prominence=1.0, width=20, \n",
    "                                     window_size=51, polyorder=3)\n",
    "        results[method] = analyze_peaks(noisy_signal, peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 1000)\n",
    "signal = 3*np.sin(x) + np.sin(5*x)\n",
    "noisy_signal2 = signal + np.random.normal(0, 0.5, signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(noisy_signal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(noisy_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of noisy_signal should be numpy.ndarray  \n",
    "noisy_signal = np.array(noisy_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(noisy_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
