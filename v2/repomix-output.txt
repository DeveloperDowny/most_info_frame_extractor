This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-30T17:23:06.954Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
ocr_approval/
  approve_all_approval_strategy.py
  ocr_approval_strategy_factory.py
  ocr_approval_strategy.py
  pixel_comparison_ocr_approval_strategy.py
scripts/
  frame_number_to_timestamp.py
  get_named_pdfs.py
utils/
  file_util.py
  image_utils.py
  text_util.py
__init__.py
.repomixignore
analyzer.py
constants.py
data_plotter.py
data_visualizer.py
directory_manager.py
easy_ocr.py
extraction_strategy_factory.py
extraction_strategy.py
file_frame.py
frame.py
helper.py
input_strategy_factory.py
input_strategy.py
k_transactions_extraction_strategy.py
key_moments_extraction_strategy.py
local_video_input_strategy.py
main.py
ocr_strategy_factory.py
ocr_strategy.py
playlist_input_strategy.py
post_processor.py
processed_frame.py
python_object_input_strategy.py
random_generator.py
tesseract_ocr.py
TODO.md
video_processor.py
youtube_video_url_input_strategy.py
yt_down.py

================================================================
Repository Files
================================================================

================
File: ocr_approval/approve_all_approval_strategy.py
================
from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy
import cv2


class ApproveAllApprovalStrategy(OCRApprovalStrategy):
    def permit_ocr(self, new_frame: cv2.Mat, old_frame: cv2.Mat) -> bool:
        return True

================
File: ocr_approval/ocr_approval_strategy_factory.py
================
from ocr_approval.pixel_comparison_ocr_approval_strategy import (
    PixelComparisonOCRApprovalStrategy,
)
from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy
from ocr_approval.approve_all_approval_strategy import ApproveAllApprovalStrategy

class OCRApprovalStrategyFactory:

    @staticmethod
    def create_strategy(input_type: str) -> OCRApprovalStrategy:
        if input_type == "pixel_comparison":
            return PixelComparisonOCRApprovalStrategy()
        elif input_type == "approve_all":
            return ApproveAllApprovalStrategy()
        else:
            raise ValueError("Invalid OCR approval strategy")

================
File: ocr_approval/ocr_approval_strategy.py
================
import cv2


class OCRApprovalStrategy:
    def permit_ocr(self, new_frame: cv2.Mat, old_frame: cv2.Mat) -> bool:
        pass

================
File: ocr_approval/pixel_comparison_ocr_approval_strategy.py
================
from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy
import cv2
from utils.image_utils import ImageUtils


class PixelComparisonOCRApprovalStrategy(OCRApprovalStrategy):
    def permit_ocr(self, new_frame: cv2.Mat, old_frame: cv2.Mat) -> bool:
        if type(old_frame) == type(None):
            return True
        return not ImageUtils.are_images_almost_equal(new_frame, old_frame)

================
File: scripts/frame_number_to_timestamp.py
================
from video_processor import VideoProcessor
from directory_manager import DirectoryManager
from helper import Helper

if __name__ == "__main__":
    directory = "data/aecnku"
    video_path = DirectoryManager.get_video_path(directory)
    frame_number = 3870
    timestamp = VideoProcessor.get_timestamp_from_frame_number(video_path, frame_number)
    print(timestamp)
    
    formatted_time = VideoProcessor.get_formatted_time(timestamp)
    print(formatted_time)

================
File: scripts/get_named_pdfs.py
================
import os
import shutil

from directory_manager import DirectoryManager
from random_generator import RandomGenerator
from utils.text_util import TextUtil
from utils.file_util import FileUtil


def get_named_pdfs(index, input, new_directory):

    directory, video_name = TextUtil.get_directory_and_video_name(input)

    pdf_path = f"data/{directory}.pdf"

    output_path = f"{new_directory}/{index + 1} {video_name}.pdf"

    shutil.copy(pdf_path, output_path)


if __name__ == "__main__":
    new_directory = RandomGenerator.generate_random_word(3)
    new_directory = f"scripts/data/{new_directory}"
    DirectoryManager.create_directory(new_directory)

    inputs = FileUtil.get_inputs("scripts/data/results.txt")

    print(inputs)

    for index, input in enumerate(inputs):
        try:
            get_named_pdfs(index, input, new_directory)
        except Exception as e:
            print(input)
            print(e)

================
File: utils/file_util.py
================
class FileUtil:
    @staticmethod
    def get_inputs(file_path):
        inputs = []
        with open(file_path, "r") as file:
            inputs = file.readlines()
        return inputs

================
File: utils/image_utils.py
================
import cv2
import numpy as np

class ImageUtils:

    @staticmethod
    def are_images_almost_equal(image1: np.ndarray, image2: np.ndarray) -> bool:
        # Convert frames to grayscale
        image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
        image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

        # Compute the absolute difference between the two frames
        diff = cv2.absdiff(image1_gray, image2_gray)

        # Threshold the difference to get a binary image
        _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)

        # Calculate the percentage of different pixels
        non_zero_count = cv2.countNonZero(thresh)
        total_pixels = image1_gray.size
        diff_percentage = (non_zero_count / total_pixels) * 100

        # If the difference is less than a certain threshold, consider the frames almost the same
        return diff_percentage < 0.5

================
File: utils/text_util.py
================
class TextUtil:
    @staticmethod
    def get_directory_and_video_name(input):
        input = input.split(" -> ")

        directory = input[0]
        directory = directory.split("/")[1]

        video_name = input[1]
        video_name = video_name.split("/")[-1]
        video_name = video_name.split(".")[0]

        return directory, video_name

================
File: __init__.py
================
import video_processor

================
File: .repomixignore
================
__pycache__
data
debug.log

================
File: analyzer.py
================
import pandas as pd
import numpy as np


class Analyzer:
    @staticmethod
    def calculate_moving_averages(df, short_window=20, long_window=50):
        df["SMA_short"] = df["char_count"].rolling(window=short_window).mean()
        df["SMA_long"] = df["char_count"].rolling(window=long_window).mean()
        df["crossover"] = np.where(df["SMA_short"] > df["SMA_long"], 1, 0)
        df["crossover_change"] = df["crossover"].diff()
        return df
    
    @staticmethod 
    def calculate_moving_average(array, window):
        return np.convolve(array, np.ones(window), 'valid') / window

================
File: constants.py
================
BASE_DIR = "data"

================
File: data_plotter.py
================
import matplotlib.pyplot as plt
from typing import List
from processed_frame import ProcessedFrame


class DataPlotter:
    @staticmethod
    def plot_data(
        x_data,
        y_data,
        x_label,
        y_label,
        title,
        output_path,
        x_ticks=None,
        y_ticks=None,
        extracted_frames: List[ProcessedFrame] = None,
    ):
        weight_y, weight_x = 10, 7
        plt.figure(figsize=(max(20, len(x_data) / weight_x), max(y_data) / weight_y))
        plt.plot(x_data, y_data, marker="o")
        plt.title(title)
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.grid(True, axis="both", linestyle="--", alpha=0.7)
        plt.xticks(x_data, rotation=45, ha="right")

        min_y, max_y = min(y_data), max(y_data)
        plt.ylim(max(0, min_y - 1), max_y + 1)
        unique_y_data = sorted(set(y_data))
        plt.yticks(unique_y_data)

        if x_ticks:
            plt.xticks(x_ticks)
        if y_ticks:
            plt.yticks(y_ticks)

        if extracted_frames:
            for frame in extracted_frames:
                plt.annotate(
                    f"Extracted Frame ({frame.frame_number})",
                    (frame.frame_number, len(frame.ocr_text)),
                    xytext=(5, 5),
                    textcoords="offset points",
                    color="green",
                    fontweight="bold",
                )
                plt.plot(
                    frame.frame_number,
                    len(frame.ocr_text),
                    "o",
                    color="green",
                    markersize=10,
                )

        plt.tight_layout()
        plt.savefig(output_path, dpi=300)
        plt.close()

================
File: data_visualizer.py
================
import pandas as pd
import matplotlib.pyplot as plt

class DataVisualizer:
    def __init__(self, df: pd.DataFrame):
        self.df = df

        weight_y = 10
        weight_x = 7
        max_chars = df["char_count"].max() / 4

        # plt.figure(figsize=( df.shape[0]  / weight_x, max_chars /weight_y))
        self.figsize = (df.shape[0] / weight_x, max_chars / weight_y)

    @staticmethod
    def plot_decorator(func):
        def wrapper(*args, **kwargs):
            # set style to normal style
            plt.style.use("classic")
            plt.figure(figsize=args[0].figsize)
            func(*args, **kwargs)
            # plt.grid(True, axis="both", linestyle="--", alpha=0.7)
            # color should be light of the grid
            plt.grid(True, axis="both", linestyle="--", alpha=0.7, color="lightgrey")
            plt.xticks(args[0].df["frame_id"], rotation=45, ha="right")

            plt.show()

        return wrapper

    @plot_decorator
    def plot_char_count(self):
        # Plot a histogram of the character count
        plt.hist(self.df["char_count"], bins=30, color="skyblue", edgecolor="black")
        plt.title("Character Count in Text")
        plt.xlabel("Character Count")
        plt.ylabel("Frequency")

    @plot_decorator
    def plot_frame_id_vs_char_count(self):
        # Plot the frame_id vs char_count
        plt.scatter(self.df["frame_id"], self.df["char_count"], color="skyblue")
        plt.title("Frame ID vs Character Count")
        plt.xlabel("Frame ID")
        plt.ylabel("Character Count")

    @plot_decorator
    def plot_frame_id_vs_char_count_line(self):
        # Plot the frame_id vs char_count with a line connecting the points
        plt.plot(self.df["frame_id"], self.df["char_count"], color="blue")
        plt.title("Frame ID vs Character Count")
        plt.xlabel("Frame ID")
        plt.ylabel("Character Count")

    @plot_decorator
    def plot_moving_averages(self):
        df = self.df
        plt.plot(
            df["frame_id"], df["char_count"], color="skyblue", label="Character Count"
        )
        plt.plot(
            df["frame_id"],
            df["SMA_short"],
            color="orange",
            label="Short Moving Average",
        )
        plt.plot(
            df["frame_id"], df["SMA_long"], color="red", label="Long Moving Average"
        )
        plt.title("Moving Averages")
        plt.xlabel("Frame ID")
        plt.ylabel("Character Count")
        plt.legend()

    @plot_decorator
    def plot_crossover_points(self, crossover_points):
        df = self.df
        self.plot_moving_averages()
        plt.scatter(
            crossover_points["frame_id"],
            crossover_points["char_count"],
            color="black",
            label="Crossover Points",
        )
        plt.title("Crossover Points")
        plt.xlabel("Frame ID")
        plt.ylabel("Character Count")
        plt.legend()

================
File: directory_manager.py
================
import os
import shutil


class DirectoryManager:
    @staticmethod
    def create_directory(directory_name: str):
        os.mkdir(directory_name)

    @staticmethod
    def delete_directory(dir_path: str):
        if os.path.exists(dir_path):
            shutil.rmtree(dir_path)

    @staticmethod
    def get_file_name(directory: str) -> str:
        return os.listdir(directory)[0]

    @staticmethod
    def get_video_path(directory: str) -> str:
        return os.path.join(directory, DirectoryManager.get_file_name(directory))

================
File: easy_ocr.py
================
from ocr_strategy import OCRStrategy
import easyocr
import cv2
import numpy as np


class EasyOCR(OCRStrategy):
    def __init__(self):
        self.reader = easyocr.Reader(["en"])

    def extract_text(self, img):
        if isinstance(img, str):
            results = self.reader.readtext(img)
        elif isinstance(img, np.ndarray):
            results = self.reader.readtext(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        text = [result[1] for result in results]
        return " ".join(text)

================
File: extraction_strategy_factory.py
================
from k_transactions_extraction_strategy import KTransactionsExtractionStrategy
from key_moments_extraction_strategy import KeyMomentsExtractionStrategy


class ExtractionStrategyFactory:
    @staticmethod
    def create_extraction_strategy(extraction_type):
        if extraction_type == "k_transactions":
            return KTransactionsExtractionStrategy()
        elif extraction_type == "key_moments":
            return KeyMomentsExtractionStrategy()
        else:
            raise ValueError("Invalid extraction type")

================
File: extraction_strategy.py
================
from processed_frame import ProcessedFrame
from typing import List


class ExtractionStrategy:
    def extract_frames(self, frames: List[ProcessedFrame]) -> List[ProcessedFrame]:
        pass

================
File: file_frame.py
================
class FileFrame:
    def __init__(self, frame_path: str): 
        self.frame_id = int(frame_path.split('_')[-1].split('.')[0])
        self.frame_path = frame_path
    
    @staticmethod
    def get_sorted_frames(list_of_files):
        frames = [FileFrame(file) for file in list_of_files]
        frames.sort(key=lambda x: x.frame_id)
        return frames

================
File: frame.py
================
import cv2

class Frame:
    def __init__(self, frame_number: int, frame: cv2.Mat):
        self.frame_number = frame_number
        self.frame = frame

================
File: helper.py
================
import re
import yt_down
from random_generator import RandomGenerator
from directory_manager import DirectoryManager
import os
from pytubefix import Playlist, YouTube
import cv2
import pickle

from constants import BASE_DIR

from math import ceil


class Helper:
    @staticmethod
    def get_digits(text: str) -> int:
        return int(re.sub(r"\D", "", text))

    @staticmethod
    def download_youtube_video(video_url: str, directory: str) -> str:

        yt_down.download_youtube_video(video_url, directory)
        video_file_name = DirectoryManager.get_video_path(directory)
        return os.path.join(directory, video_file_name)

    @staticmethod
    def save_image(frame_output_path, frame_number, video_path):
        cap = cv2.VideoCapture(video_path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
        ret, frame = cap.read()
        cv2.imwrite(frame_output_path, frame)
        cap.release()
        cv2.destroyAllWindows()

    @staticmethod
    def save_extracted_frames(extracted_frames, video_path, extracted_frames_directory):
        cap = cv2.VideoCapture(video_path)
        for frame in extracted_frames:
            frame_output_path = os.path.join(
                extracted_frames_directory, f"frame_{frame.frame_number}.jpg"
            )
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame.frame_number)
            ret, frame = cap.read()
            cv2.imwrite(frame_output_path, frame)
        cap.release()

    @staticmethod
    def clean_text(text: str) -> str:
        # Replace multiple whitespaces with a single space

        # Remove punctuation and special characters
        text = re.sub(r"[^a-zA-Z0-9 ]", " ", text)
        text = re.sub(r"\s+", " ", text)
        text = text.strip()
        text = text.lower()

        return text

    @staticmethod
    def save_python_objects(python_objects, python_object_path):
        with open(python_object_path, "wb") as f:
            pickle.dump(python_objects, f)

    @staticmethod
    def save_text(text, text_file_path):
        with open(text_file_path, "w") as f:
            f.write(text)

    @staticmethod
    def append_text(text, text_file_path):
        with open(text_file_path, "a") as f:
            f.write(text)

    @staticmethod
    def index_results(directory, video_file_path):
        formatted_text = f"\n{directory} -> {video_file_path}"
        result_file_path = os.path.join(BASE_DIR, "results.txt")
        Helper.append_text(formatted_text, result_file_path)

    @staticmethod
    def load_python_object(python_object_path):
        with open(python_object_path, "rb") as f:
            return pickle.load(f)

    @staticmethod
    def load_text(text_file_path):
        with open(text_file_path, "r") as f:
            return f.read()

    @staticmethod
    def get_video_urls_from_playlist(playlist_url: str) -> list:
        playlist = Playlist(playlist_url)
        return playlist.video_urls

    @staticmethod
    def get_video_duration(video_url: str) -> int:
        """
        Get the duration of a video.

        Args:
            video_url (str): The URL of the video.

        Returns:
            int: The duration of the video in seconds.
        """

        # TODO: Call the YouTube API to get the duration of the video
        video = YouTube(video_url)

        return video.length

    @staticmethod
    def get_number_of_slides(video_duration: int, seconds_per_slide: int = 30) -> int:
        """
        Get the number of slides in a video.

        Args:
            video_duration (int): The duration of the video in seconds.
            seconds_per_slide (int): The number of seconds per slide. Defaults to 10.

        Returns:
            int: The number of slides in the video.
        """

        return ceil(video_duration / seconds_per_slide)

    @staticmethod
    def get_key_moments(video_url: str) -> list:
        video = YouTube(video_url)
        key_moments = video.key_moments
        key_moment_start_seconds = [
            key_moment.start_seconds for key_moment in key_moments
        ]
        return key_moment_start_seconds

    @staticmethod
    def get_frame_number_from_seconds(seconds: int, frame_rate: int) -> int:
        return seconds * frame_rate

    @staticmethod
    def get_key_moments_from_seconds(key_moments, frame_rate):
        return [
            Helper.get_frame_number_from_seconds(key_moment, frame_rate)
            for key_moment in key_moments
        ]

    @staticmethod
    def log(message: str):
        print(message)

    def save_objects(video_path, processed_frames, directory):
        python_object_directory = directory + "_python_object"
        DirectoryManager.create_directory(python_object_directory)
        python_object_path = os.path.join(
            python_object_directory, "processed_frames.pkl"
        )
        video_path_text_file_path = os.path.join(
            python_object_directory, "video_path.txt"
        )
        Helper.save_text(video_path, video_path_text_file_path)
        Helper.save_python_objects(processed_frames, python_object_path)

    @staticmethod
    def get_video_name(video_path):
        video_name = os.path.basename(video_path)
        return video_name

    @staticmethod
    def save_log(video_path, output_pdf_path):
        video_name = Helper.get_video_name(video_path)
        Helper.log(f"Saved PDF to {output_pdf_path} for {video_name}")

    @staticmethod
    def get_frame_rate(video_path):
        cap = cv2.VideoCapture(video_path)
        frame_rate = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        cv2.destroyAllWindows()
        return frame_rate


if __name__ == "__main__":
    print(Helper.get_digits("frame_234.jpg"))

================
File: input_strategy_factory.py
================
from youtube_video_url_input_strategy import YouTubeVideoURLInputStrategy
from input_strategy import InputStrategy
from local_video_input_strategy import LocalVideoInputStrategy
from python_object_input_strategy import PythonObjectInputStrategy
from playlist_input_strategy import PlaylistInputStrategy


class InputStrategyFactory:

    @staticmethod
    def create_input_strategy(
        input_type, ocr_strategy, extraction_strategy, ocr_approval_strategy
    ) -> InputStrategy:
        if input_type == "youtube":
            video_url = input("Enter YouTube video URL: ")
            return YouTubeVideoURLInputStrategy(
                video_url, ocr_strategy, extraction_strategy, ocr_approval_strategy
            )
        elif input_type == "local":
            directory = input("Enter directory path: ")
            return LocalVideoInputStrategy(
                directory, ocr_strategy, extraction_strategy, ocr_approval_strategy
            )
        elif input_type == "object":
            """The directory path should be like this `xxxxxx_python_object`"""
            directory = input("Enter directory path: ")
            return PythonObjectInputStrategy(
                directory, ocr_strategy, extraction_strategy
            )
        elif input_type == "playlist":
            playlist_url = input("Enter YouTube playlist URL: ")
            start_from = int(input("Enter start from: "))

            return PlaylistInputStrategy(
                playlist_url,
                start_from,
                ocr_strategy,
                extraction_strategy,
                ocr_approval_strategy,
            )
        else:
            raise ValueError("Invalid input type")

================
File: input_strategy.py
================
class InputStrategy:
    def proceed(self):
        pass

================
File: k_transactions_extraction_strategy.py
================
from extraction_strategy import ExtractionStrategy
import pandas as pd
from processed_frame import ProcessedFrame
from scipy import signal
import numpy as np
from scipy.ndimage import gaussian_filter1d

from typing import List


class KTransactionsExtractionStrategy(ExtractionStrategy):
    def __init__(self):
        self.k = None
        self.auto_calculate_k = False

    def calculate_peaks(self, x, y, window_size=5, prominence=0.1, width=None):
        """
        Calculate signal peaks after smoothing.

        Parameters:
        x: array-like, x coordinates of the signal
        y: array-like, y coordinates of the signal
        window_size: int, size of the moving average window
        prominence: float, required prominence of peaks
        width: float or None, required width of peaks
        """
        # Convert inputs to numpy arrays
        x = np.array(x)
        y = np.array(y)

        # Apply Gaussian smoothing to reduce noise
        y_smoothed = gaussian_filter1d(y, sigma=window_size / 3)

        # Apply moving average
        kernel = np.ones(window_size) / window_size
        y_smoothed = np.convolve(y_smoothed, kernel, mode="same")

        # Find peaks in the smoothed signal
        peaks, properties = signal.find_peaks(
            y_smoothed,
            prominence=prominence * (np.max(y_smoothed) - np.min(y_smoothed)),
            width=width,
        )

        return peaks, y_smoothed

    @staticmethod
    def maxProfit(prices, n, k):
        if n <= 1 or k == 0:
            return 0, []

        profit = [[0 for _ in range(k + 1)] for _ in range(n)]
        transactions = [[[] for _ in range(k + 1)] for _ in range(n)]

        for i in range(1, n):
            for j in range(1, k + 1):
                max_so_far = 0
                best_transaction = []

                for l in range(i):
                    current_profit = prices[i] - prices[l] + profit[l][j - 1]
                    if current_profit > max_so_far:
                        max_so_far = current_profit
                        best_transaction = transactions[l][j - 1] + [(l, i)]

                if max_so_far > profit[i - 1][j]:
                    profit[i][j] = max_so_far
                    transactions[i][j] = best_transaction
                else:
                    profit[i][j] = profit[i - 1][j]
                    transactions[i][j] = transactions[i - 1][j]

        return profit[n - 1][k], transactions[n - 1][k]

    def extract_frames(self, frames: List[ProcessedFrame]) -> List[ProcessedFrame]:
        # Create the signal from frames
        data = [(frame.frame_number, frame.ocr_text) for frame in frames]
        df = pd.DataFrame(data, columns=["frame_id", "text"])
        df["char_count"] = df["text"].apply(len)

        # Generate x and y coordinates for signal processing
        x = df.index.values
        y = df["char_count"].values

        if self.auto_calculate_k:
            # Calculate k using signal processing
            peaks, _ = self.calculate_peaks(x, y)
            # Set k as the number of detected peaks
            # self.k = len(peaks) #+ 10
            self.k = len(peaks) + 5
            print(f"Detected {self.k} significant transitions in the signal")
        
        else:
            # Calculate k using signal processing if not already set
            if self.k is None:
                should_auto_calculate_or_k = input(
                    "Enter 'auto' to auto-calculate k or enter k: "
                )
                if should_auto_calculate_or_k == "auto":
                    peaks, _ = self.calculate_peaks(x, y)
                    # Set k as the number of detected peaks
                    self.k = len(peaks)
                    print(f"Detected {self.k} significant transitions in the signal")
                else:
                    self.k = int(should_auto_calculate_or_k)

        # Proceed with the original maxProfit calculation
        prices = df["char_count"].values
        n = len(prices)
        max_profit, transactions = self.maxProfit(prices, n, self.k)

        return [frames[sell] for _, sell in transactions]

================
File: key_moments_extraction_strategy.py
================
from extraction_strategy import ExtractionStrategy
from helper import Helper
from processed_frame import ProcessedFrame
from typing import List

class KeyMomentsExtractionStrategy(ExtractionStrategy):
    def __init__(self):
        self.video_url = None
        self.frame_rate = None

    def extract_frames(self, frames: List[ProcessedFrame]) -> List[ProcessedFrame]:
        key_moments = Helper.get_key_moments(self.video_url)
        key_frame_numbers = Helper.get_key_moments_from_seconds(key_moments, self.frame_rate)
        key_frames = []

        for frame_number in key_frame_numbers:
            processed_frame = ProcessedFrame()
            processed_frame.frame_number = frame_number
            key_frames.append(processed_frame)
        
        return key_frames
        

        # below code won't work cause interval is 3 in our case and here the interval is 1 (for frames from key_moments)
        # key_frames = []
        # i = 0
        # j = 0

        # n = len(frames)
        # m = len(key_frame_numbers)

        # while j < m:
        #     while frames[i].frame_number < key_frame_numbers[j] and i < n:
        #         i += 1
            
        #     if frames[i].frame_number == key_frame_numbers[j]:
        #         key_frames.append(frames[i])
            
        #     j += 1
        
        # return key_frames

================
File: local_video_input_strategy.py
================
from input_strategy import InputStrategy
from processed_frame import ProcessedFrame
from ocr_strategy import OCRStrategy
from extraction_strategy import ExtractionStrategy
from data_plotter import DataPlotter
from random_generator import RandomGenerator
from directory_manager import DirectoryManager
import os
from helper import Helper
from post_processor import PostProcessor

from constants import BASE_DIR

from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy


class LocalVideoInputStrategy(InputStrategy):
    def __init__(
        self,
        directory: str,
        ocr_strategy: OCRStrategy,
        extraction_strategy: ExtractionStrategy,
        ocr_approval_strategy: OCRApprovalStrategy,
    ):
        self.directory = os.path.join(BASE_DIR, directory)
        self.ocr_strategy = ocr_strategy
        self.extraction_strategy = extraction_strategy
        self.ocr_approval_strategy = ocr_approval_strategy

    def proceed(self):
        suffix = RandomGenerator.generate_random_word(3)
        new_directory = self.directory + "_" + suffix
        DirectoryManager.create_directory(new_directory)

        Helper.log(f"Created {new_directory}")

        video_path = DirectoryManager.get_video_path(self.directory)

        Helper.index_results(new_directory, video_path)

        processed_frames = ProcessedFrame.from_video(
            video_path, self.ocr_strategy, self.ocr_approval_strategy
        )

        Helper.log(f"Processed {len(processed_frames)} frames")

        Helper.save_objects(video_path, processed_frames, new_directory)

        x_data, y_data = ProcessedFrame.get_data_for_plotting(processed_frames)

        plot_directory = new_directory + "_plot"
        DirectoryManager.create_directory(plot_directory)
        plot_output_path = os.path.join(plot_directory, "plot.png")

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
        )

        extracted_frames = self.extraction_strategy.extract_frames(processed_frames)

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
            extracted_frames=extracted_frames,
        )

        extracted_frames_directory = new_directory + "_extracted_frames"
        DirectoryManager.create_directory(extracted_frames_directory)

        Helper.save_extracted_frames(
            extracted_frames, video_path, extracted_frames_directory
        )

        Helper.log(f"Extracted frames to {extracted_frames_directory}")

        list_of_files = os.listdir(extracted_frames_directory)

        PostProcessor.add_text_to_frames_and_save(
            extracted_frames_directory, list_of_files, extracted_frames_directory
        )

        output_pdf_path = new_directory + ".pdf"
        PostProcessor.convert_images_to_pdf(
            extracted_frames_directory, list_of_files, output_pdf_path
        )

        Helper.save_log(video_path, output_pdf_path)

================
File: main.py
================
from input_strategy_factory import InputStrategyFactory
from ocr_strategy_factory import OCRStrategyFactory
from extraction_strategy_factory import ExtractionStrategyFactory
from input_strategy import InputStrategy
from ocr_approval.ocr_approval_strategy_factory import OCRApprovalStrategyFactory


def main():
    ocr_approval_type = "pixel_comparison"
    # ocr_approval_type = "approve_all"
    ocr_approval_strategy = OCRApprovalStrategyFactory.create_strategy(
        ocr_approval_type
    )

    # ocr_type = input("Enter OCR type: ")
    # ocr_type = "tesseract"
    ocr_type = "easy"
    ocr_strategy = OCRStrategyFactory.create_ocr_strategy(ocr_type)

    extraction_type = "k_transactions"
    # extraction_type = "key_moments"
    extraction_strategy = ExtractionStrategyFactory.create_extraction_strategy(
        extraction_type
    )

    # input_type = input("Enter input type: ")
    input_type = "youtube"
    # input_type = "playlist"
    # input_type = "local"
    # input_type = "object"
    input_strategy: InputStrategy = InputStrategyFactory.create_input_strategy(
        input_type, ocr_strategy, extraction_strategy, ocr_approval_strategy
    )
    input_strategy.proceed()


if __name__ == "__main__":
    main()

================
File: ocr_strategy_factory.py
================
from tesseract_ocr import Tesseract
from easy_ocr import EasyOCR

class OCRStrategyFactory:
    @staticmethod
    def create_ocr_strategy(ocr_type):
        if ocr_type == "tesseract":
            return Tesseract()
        elif ocr_type == "easy":
            return EasyOCR()
        else:
            raise ValueError("Invalid OCR type")

================
File: ocr_strategy.py
================
from helper import Helper

class OCRStrategy:
    def extract_text(self, image):
        pass
    def extract_clean_text(self, image):
        text = self.extract_text(image)
        return Helper.clean_text(text)

================
File: playlist_input_strategy.py
================
from input_strategy import InputStrategy
from ocr_strategy import OCRStrategy
from extraction_strategy import ExtractionStrategy
from random_generator import RandomGenerator
from directory_manager import DirectoryManager
import os
from helper import Helper
from constants import BASE_DIR
from youtube_video_url_input_strategy import YouTubeVideoURLInputStrategy
from k_transactions_extraction_strategy import KTransactionsExtractionStrategy
from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy


class PlaylistInputStrategy(InputStrategy):
    def __init__(
        self,
        playlist_url: str,
        start_from: int,
        ocr_strategy: OCRStrategy,
        extraction_strategy: ExtractionStrategy,
        ocr_approval_strategy: OCRApprovalStrategy,
    ):
        self.playlist_url = playlist_url

        "The video number to start processing from. Skip the previous videos."
        self.start_from = start_from
        self.ocr_strategy = ocr_strategy
        self.extraction_strategy = extraction_strategy
        self.ocr_approval_strategy = ocr_approval_strategy

    def proceed(self):
        directory = RandomGenerator.generate_random_word(6)
        directory = os.path.join(BASE_DIR, directory)
        DirectoryManager.create_directory(directory)

        video_urls = Helper.get_video_urls_from_playlist(self.playlist_url)
        counter = 0
        for video_url in video_urls:
            print("\n\n\n=====================================")
            print(f"#{self.start_from + counter} Processing video: {video_url}")
            print("=====================================")
            counter += 1
            if counter < self.start_from:
                continue
            
            # TODO: Ideally, this should not be here. Check if there is a better way to do this.
            if isinstance(self.extraction_strategy, KTransactionsExtractionStrategy):
                # TODO: This is a hack. Fix this.
                # video_duration = Helper.get_video_duration(video_url)
                # number_of_slides = Helper.get_number_of_slides(video_duration)
                # self.extraction_strategy.k = number_of_slides
                self.extraction_strategy.auto_calculate_k = True 

            video_input_strategy = YouTubeVideoURLInputStrategy(
                video_url,
                self.ocr_strategy,
                self.extraction_strategy,
                self.ocr_approval_strategy,
            )

            video_input_strategy.proceed()

================
File: post_processor.py
================
import os
import cv2
from PIL import Image
from helper import Helper
from directory_manager import DirectoryManager
from file_frame import FileFrame as Frame


class PostProcessor:
    @staticmethod
    def add_text_to_frames_and_save(input_dir, list_of_files, output_dir):
        frames = Frame.get_sorted_frames(list_of_files)

        n = len(frames)
        for i, frame in enumerate(frames):
            frame_path = os.path.join(input_dir, frame.frame_path)
            current_frame = cv2.imread(frame_path)

            text = f"Glimpsify {i+1}/{n}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            text_size, _ = cv2.getTextSize(text, font, 0.51, 1)
            text_x = 10
            text_y = current_frame.shape[0] - 10

            overlay = current_frame.copy()

            # Draw the filled rectangle on the overlay image
            cv2.rectangle(
                overlay,
                (text_x, text_y - text_size[1] - 10),
                (text_x + text_size[0], text_y),
                (85, 26, 58),
                cv2.FILLED,
            )
            cv2.putText(
                overlay,
                text,
                (text_x, text_y - 5),
                font,
                0.5,
                (255, 255, 255),
                1,
                cv2.LINE_AA,
            )

            # Blend the overlay with the original image using alpha blending
            opacity = 0.6
            cv2.addWeighted(
                overlay, opacity, current_frame, 1 - opacity, 0, current_frame
            )

            output_path = os.path.join(output_dir, frame.frame_path)
            cv2.imwrite(output_path, current_frame)

    @staticmethod
    def convert_images_to_pdf(input_dir, list_of_files, output_pdf_path):
        frames = [Frame(file) for file in list_of_files]
        frames.sort(key=lambda x: x.frame_id)

        images = []
        first_image = None

        for frame in frames:
            image_path = os.path.join(input_dir, frame.frame_path)
            img = Image.open(image_path)

            if img.mode == "RGBA":
                img = img.convert("RGB")

            if first_image is None:
                first_image = img
            else:
                images.append(img)

        if first_image:
            first_image.save(output_pdf_path, save_all=True, append_images=images)
            return True
        return False


if __name__ == "__main__":
    input_dir = "data/lrpdqi_profits"
    output_dir = "data/lrpdqi_profits_postprocessed"
    pdf_output_path = "data/lrpdqi_profits.pdf"

    DirectoryManager.create_directory(output_dir)

    list_of_files = os.listdir(input_dir)

    # Process and save individual frames
    PostProcessor.add_text_to_frames_and_save(input_dir, list_of_files, output_dir)

    # Convert processed images to PDF
    processed_files = os.listdir(output_dir)
    if PostProcessor.convert_images_to_pdf(
        output_dir, processed_files, pdf_output_path
    ):
        print(f"PDF successfully created at {pdf_output_path}")
    else:
        print("Failed to create PDF - no images found")

================
File: processed_frame.py
================
import os
from helper import Helper
from ocr_strategy import OCRStrategy
from video_processor import VideoProcessor
from directory_manager import DirectoryManager
from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy


class ProcessedFrame:
    def __init__(self):
        self.frame_number = 0
        self.ocr_text = ""

    @staticmethod
    def from_directory(directory, ocr_strategy: OCRStrategy):
        processed_frames = []
        for filename in os.listdir(directory):
            if filename.endswith(".jpg"):
                frame = ProcessedFrame()
                frame.frame_number = Helper.get_digits(filename)
                frame.ocr_text = ocr_strategy.extract_clean_text(
                    os.path.join(directory, filename)
                )
                processed_frames.append(frame)

    @staticmethod
    def from_video(video_path, ocr_strategy: OCRStrategy, ocr_approval_strategy: OCRApprovalStrategy):
        processed_frames = []
        old_frame = None
        for frame in VideoProcessor.get_frames(video_path, 3):
            
            if not ocr_approval_strategy.permit_ocr(frame.frame, old_frame):
                # result should be same as previous frame
                processed_frame = ProcessedFrame()
                processed_frame.frame_number = frame.frame_number
                processed_frame.ocr_text = processed_frames[-1].ocr_text
                processed_frames.append(processed_frame)
                continue
            old_frame = frame.frame

            processed_frame = ProcessedFrame()
            processed_frame.frame_number = frame.frame_number
            processed_frame.ocr_text = ocr_strategy.extract_clean_text(frame.frame)
            processed_frames.append(processed_frame)
        return processed_frames

    @staticmethod
    def from_youtube_video(video_url, directory, ocr_strategy: OCRStrategy):

        Helper.download_youtube_video(video_url, directory)
        video_path = DirectoryManager.get_video_path(directory)
        return ProcessedFrame.from_video(video_path, ocr_strategy)

    @staticmethod
    def get_data_for_plotting(processed_frames):
        x_data = [frame.frame_number for frame in processed_frames]
        y_data = [len(frame.ocr_text) for frame in processed_frames]
        return x_data, y_data


# This section will come in input strategy or something maybe
# @staticmethod
# def from_youtube_playlist(
#     playlist_url, ocr_strategy: OCRStrategy, video_processor: VideoProcessor
# ):
#     directory = RandomGenerator.generate_random_word(6)
#     DirectoryManager.create_directory(directory)
#     video_urls = Helper.get_youtube_playlist_urls(playlist_url)
#     for video_url in video_urls:
#         processed_frames = ProcessedFrame.from_youtube_video(
#             video_url, ocr_strategy, video_processor
#         )

================
File: python_object_input_strategy.py
================
from input_strategy import InputStrategy
from processed_frame import ProcessedFrame
from ocr_strategy import OCRStrategy
from extraction_strategy import ExtractionStrategy
from data_plotter import DataPlotter
from random_generator import RandomGenerator
from directory_manager import DirectoryManager
import os
from helper import Helper
from post_processor import PostProcessor

from constants import BASE_DIR


class PythonObjectInputStrategy(InputStrategy):
    def __init__(
        self,
        directory: str,
        ocr_strategy: OCRStrategy,
        extraction_strategy: ExtractionStrategy,
    ):
        self.directory = os.path.join(BASE_DIR, directory)
        self.ocr_strategy = ocr_strategy
        self.extraction_strategy = extraction_strategy

    def proceed(self):
        new_directory = RandomGenerator.generate_random_word(6)
        new_directory = os.path.join(BASE_DIR, new_directory)
        DirectoryManager.create_directory(new_directory)

        video_path_file_path = os.path.join(self.directory, "video_path.txt")
        video_path = Helper.load_text(video_path_file_path)

        Helper.index_results(new_directory, video_path)

        python_object_path = os.path.join(self.directory, "processed_frames.pkl")
        processed_frames = Helper.load_python_object(python_object_path)

        Helper.log(f"Loaded {len(processed_frames)} frames")

        x_data, y_data = ProcessedFrame.get_data_for_plotting(processed_frames)

        plot_directory = new_directory + "_plot"
        DirectoryManager.create_directory(plot_directory)
        plot_output_path = os.path.join(plot_directory, "plot.png")

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
        )

        Helper.log(f"Plotted data to {plot_output_path}")

        extracted_frames = self.extraction_strategy.extract_frames(processed_frames)

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
            extracted_frames=extracted_frames,
        )

        extracted_frames_directory = new_directory + "_extracted_frames"
        DirectoryManager.create_directory(extracted_frames_directory)

        Helper.save_extracted_frames(
            extracted_frames, video_path, extracted_frames_directory
        )

        Helper.log(f"Extracted frames to {extracted_frames_directory}")

        list_of_files = os.listdir(extracted_frames_directory)

        PostProcessor.add_text_to_frames_and_save(
            extracted_frames_directory, list_of_files, extracted_frames_directory
        )

        output_pdf_path = new_directory + ".pdf"
        PostProcessor.convert_images_to_pdf(
            extracted_frames_directory, list_of_files, output_pdf_path
        )

        Helper.save_log(video_path, output_pdf_path)

================
File: random_generator.py
================
import string
import random

class RandomGenerator:
    @staticmethod
    def generate_random_word(length: int) -> str:
        letters = string.ascii_lowercase
        return ''.join(random.choice(letters) for _ in range(length))

================
File: tesseract_ocr.py
================
from ocr_strategy import OCRStrategy
import pytesseract
from PIL import Image
import cv2
import numpy as np

class Tesseract(OCRStrategy):
    def extract_text(self, img): 
        if isinstance(img, str):
            return pytesseract.image_to_string(Image.open(img))
        elif isinstance(img, np.ndarray):
            return pytesseract.image_to_string(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))

================
File: TODO.md
================
Microsoft Windows [Version 10.0.22631.4460]
(c) Microsoft Corporation. All rights reserved.

D:\DPythonProjects\yt_summarizer\v2>git status
On branch vedant-panchal/fix/low-quality-images
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
        modified:   helper.py
        modified:   k_transactions_extraction_strategy.py
        modified:   main.py
        modified:   playlist_input_strategy.py
        modified:   scripts/frame_number_to_timestamp.py
        modified:   video_processor.py

no changes added to commit (use "git add" and/or "git commit -a")

D:\DPythonProjects\yt_summarizer\v2>code ..

D:\DPythonProjects\yt_summarizer\v2>python main,py
Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.

D:\DPythonProjects\yt_summarizer\v2>conda activate

(base) D:\DPythonProjects\yt_summarizer\v2>python main.py
Enter YouTube playlist URL: https://www.youtube.com/playlist?list=PLBlnK6fEyqRgJU3EsOYDTW7m6SUmW6kIIhttps://www.youtube.com/playlist?list=PLBlnK6fEyqRgJU3EsOYDTW7m6SUmW6kIITraceback (most recent call last):
  File "D:\DPythonProjects\yt_summarizer\v2\main.py", line 38, in <module>
    main()
  File "D:\DPythonProjects\yt_summarizer\v2\main.py", line 31, in main
    input_strategy: InputStrategy = InputStrategyFactory.create_input_strategy(
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\DPythonProjects\yt_summarizer\v2\input_strategy_factory.py", line 31, in create_input_strategy
    playlist_url = input("Enter YouTube playlist URL: ")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
EOFError

(base) D:\DPythonProjects\yt_summarizer\v2>python main.py
Enter YouTube playlist URL: https://www.youtube.com/playlist?list=PLBlnK6fEyqRgJU3EsOYDTW7m6SUmW6kII
Enter start from: 1



=====================================
#1 Processing video: https://www.youtube.com/watch?v=JoeiLuFNBc4
=====================================
Downloading video: Introduction to Cryptography and Network Security
Download completed successfully!
Downloaded video to data\bsyniz
Processed 206 frames
Detected 8 significant transitions in the signal
Extracted frames to data\bsyniz_extracted_frames
Saved PDF to data\bsyniz.pdf for Introduction to Cryptography and Network Security.mp4



=====================================
#2 Processing video: https://www.youtube.com/watch?v=gx0vlRpdFnc
=====================================
Downloading video: CIA Triad
Download completed successfully!
Downloaded video to data\zzdpma
Processed 323 frames
Detected 9 significant transitions in the signal
Extracted frames to data\zzdpma_extracted_frames
Saved PDF to data\zzdpma.pdf for CIA Triad.mp4



=====================================
#3 Processing video: https://www.youtube.com/watch?v=UG26SS9pjwE
=====================================
Downloading video: The OSI Security Architecture
Download completed successfully!
Downloaded video to data\zhpkpg
Processed 174 frames
Detected 9 significant transitions in the signal
Extracted frames to data\zhpkpg_extracted_frames
Saved PDF to data\zhpkpg.pdf for The OSI Security Architecture.mp4



=====================================
#4 Processing video: https://www.youtube.com/watch?v=yIm0Ol9Dg4Y
=====================================
Downloading video: Security Attacks
Download completed successfully!
Downloaded video to data\icmrdf
forrtl: error (200): program aborting due to control-C event
Image              PC                Routine            Line        Source
libifcoremd.dll    00007FFCB30CDF54  Unknown               Unknown  Unknown
KERNELBASE.dll     00007FFD2EE6DC07  Unknown               Unknown  Unknown
KERNEL32.DLL       00007FFD2F46259D  Unknown               Unknown  Unknown
ntdll.dll          00007FFD3178AF38  Unknown               Unknown  Unknown
QObject::~QObject: Timers cannot be stopped from another thread

(base) D:\DPythonProjects\yt_summarizer\v2>

================
File: video_processor.py
================
import cv2
from typing import Iterator
from frame import Frame


class VideoProcessor:

    @staticmethod
    def get_frames(video_path: str, interval: int) -> Iterator[Frame]:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_interval = int(fps * interval)

        try:
            frame_number = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                if frame_number % frame_interval == 0:
                    yield Frame(frame_number, frame)

                frame_number += 1
        finally:
            cap.release()

    
    @staticmethod
    def get_timestamp_from_frame_number(video_path: str, frame_number: int) -> float:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        timestamp = frame_number / fps
        cap.release()
        return timestamp
    
    @staticmethod
    def get_formatted_time(seconds: int) -> str:
        minutes, seconds = divmod(seconds, 60)
        hours, minutes = divmod(minutes, 60)
        return f"{hours:02.0f}:{minutes:02.0f}:{seconds:02.0f}"

================
File: youtube_video_url_input_strategy.py
================
from input_strategy import InputStrategy
from processed_frame import ProcessedFrame
from ocr_strategy import OCRStrategy
from extraction_strategy import ExtractionStrategy
from data_plotter import DataPlotter
from random_generator import RandomGenerator
from directory_manager import DirectoryManager
import os
from helper import Helper
from post_processor import PostProcessor

from constants import BASE_DIR

from key_moments_extraction_strategy import KeyMomentsExtractionStrategy

from ocr_approval.ocr_approval_strategy import OCRApprovalStrategy


class YouTubeVideoURLInputStrategy(InputStrategy):
    def __init__(
        self,
        video_url: str,
        ocr_strategy: OCRStrategy,
        extraction_strategy: ExtractionStrategy,
        ocr_approval_strategy: OCRApprovalStrategy,
    ):
        self.video_url = video_url
        self.ocr_strategy = ocr_strategy
        self.extraction_strategy = extraction_strategy
        self.ocr_approval_strategy = ocr_approval_strategy

    def proceed(self):
        directory = RandomGenerator.generate_random_word(6)
        directory = os.path.join(BASE_DIR, directory)
        DirectoryManager.create_directory(directory)

        Helper.download_youtube_video(self.video_url, directory)

        Helper.log(f"Downloaded video to {directory}")

        video_path = DirectoryManager.get_video_path(directory)

        Helper.index_results(directory, video_path)

        processed_frames = ProcessedFrame.from_video(video_path, self.ocr_strategy, self.ocr_approval_strategy)

        Helper.save_objects(video_path, processed_frames, directory)

        Helper.log(f"Processed {len(processed_frames)} frames")

        x_data, y_data = ProcessedFrame.get_data_for_plotting(processed_frames)

        plot_directory = directory + "_plot"
        DirectoryManager.create_directory(plot_directory)
        plot_output_path = os.path.join(plot_directory, "plot.png")

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
        )

        # TODO: Ideally, this should not be here. Check if there is a better way to do this.
        if isinstance(self.extraction_strategy, KeyMomentsExtractionStrategy):
            self.extraction_strategy.video_url = self.video_url
            self.extraction_strategy.frame_rate = Helper.get_frame_rate(video_path)

        extracted_frames = self.extraction_strategy.extract_frames(processed_frames)

        DataPlotter.plot_data(
            x_data,
            y_data,
            "Frame Number",
            "Number of Characters",
            "Number of Characters in OCR Text",
            plot_output_path,
            extracted_frames=extracted_frames,
        )

        extracted_frames_directory = directory + "_extracted_frames"
        DirectoryManager.create_directory(extracted_frames_directory)

        Helper.save_extracted_frames(
            extracted_frames, video_path, extracted_frames_directory
        )

        Helper.log(f"Extracted frames to {extracted_frames_directory}")

        list_of_files = os.listdir(extracted_frames_directory)

        PostProcessor.add_text_to_frames_and_save(
            extracted_frames_directory, list_of_files, extracted_frames_directory
        )

        output_pdf_path = directory + ".pdf"
        PostProcessor.convert_images_to_pdf(
            extracted_frames_directory, list_of_files, output_pdf_path
        )

        Helper.save_log(video_path, output_pdf_path)

================
File: yt_down.py
================
import os
from typing import Optional
from pytubefix import YouTube
import pytubefix

def download_youtube_video(url: str, output_dir: str = ".") -> None:
    """
    Download a YouTube video in MP4 format.

    Args:
        url (str): The URL of the YouTube video.
        output_dir (str, optional): The directory to save the downloaded video. Defaults to the current directory.
    """
    yt = YouTube(url)

    video = get_highest_resolution_mp4_stream(yt)

    if video:
        print(f"Downloading video: {yt.title}")
        try:
            video.download(output_dir)
            print("Download completed successfully!")
        except Exception as e:
            print(f"Error occurred during download: {e}")
    else:
        print("No MP4 stream found.")

def get_highest_resolution_mp4_stream(yt: YouTube) -> Optional[pytubefix.Stream]:
    """
    Get the highest resolution MP4 stream for the given YouTube object.

    Args:
        yt (YouTube): The YouTube object.

    Returns:
        Optional[pytubefix.Stream]: The highest resolution MP4 stream, or None if not found.
    """
    return yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()

if __name__ == "__main__":
    video_url = "https://www.youtube.com/watch?v=OvvTD5rtnNA&list=PLO4kDC0EWkeCnf8PBRk7XDPhrzmAxHLah&index=8"  # Replace with your desired video URL
    output_directory = os.path.join(os.getcwd(), "data")  # Change this to your desired output directory

    download_youtube_video(video_url, output_directory)
